{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_directory = 'D:/data science/cats and dogs/train'\n",
    "test_data_directory = 'D:/data science/cats and dogs/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_gap(MODEL, image_size, lambda_func=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = tf.keras.Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = lambda_func(x)\n",
    "    \n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = tf.keras.Model(base_model.input, tf.keras.layers.GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2)\n",
    "    train_generator = gen.flow_from_directory(train_data_directory, image_size, shuffle=False, \n",
    "                                              batch_size=batch_size, class_mode='binary')\n",
    "    test_generator = gen.flow_from_directory(test_data_directory, image_size, shuffle=False, \n",
    "                                             batch_size=batch_size, class_mode='binary')\n",
    "\n",
    "    print('calculating training set')\n",
    "    train = model.predict(train_generator, len(train_generator))\n",
    "    print('calculating test set')\n",
    "    test = model.predict(test_generator, len(test_generator))\n",
    "    print('write file to disk')\n",
    "    with h5py.File(f\"C:/Users/jiahu/Documents/dogs vs cats/tensorflow/features/gap_{model_name}.h5\", 'w') as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "calculating training set\n",
      "calculating test set\n",
      "write file to disk\n",
      "Wall time: 10min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NASNetLarge \n",
    "# nasnet.preprocess_input\n",
    "image_size = (331,331)\n",
    "batch_size = 8\n",
    "model_name = 'NASNetLarge'\n",
    "write_gap(tf.keras.applications.NASNetLarge, image_size, lambda_func=tf.keras.applications.nasnet.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "calculating training set\n",
      "calculating test set\n",
      "write file to disk\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# VGG16\n",
    "# vgg16.preprocess_input\n",
    "image_size = (224,224)\n",
    "batch_size = 8\n",
    "model_name = 'VGG16'\n",
    "write_gap(tf.keras.applications.VGG16, image_size, tf.keras.applications.vgg16.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "calculating training set\n",
      "calculating test set\n",
      "write file to disk\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Xception\n",
    "# xception.preprocess_input\n",
    "image_size = (299,299)\n",
    "batch_size = 64\n",
    "model_name = 'Xception'\n",
    "write_gap(tf.keras.applications.Xception, image_size, tf.keras.applications.xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "calculating training set\n",
      "calculating test set\n",
      "write file to disk\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# InceptionV3\n",
    "# inception_v3.preprocess_input\n",
    "image_size = (299,299)\n",
    "batch_size = 4\n",
    "model_name = 'InceptionV3'\n",
    "write_gap(tf.keras.applications.InceptionV3, image_size, tf.keras.applications.inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "calculating training set\n",
      "calculating test set\n",
      "write file to disk\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#ResNet50\n",
    "# resnet50.preprocess_input\n",
    "image_size = (224,224)\n",
    "batch_size = 8\n",
    "model_name = 'ResNet50'\n",
    "write_gap(tf.keras.applications.ResNet50, image_size, tf.keras.applications.resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2021)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for filename in [\"C:/Users/jiahu/Documents/dogs vs cats/tensorflow/features/gap_ResNet50.h5\", \n",
    "                 \"C:/Users/jiahu/Documents/dogs vs cats/tensorflow/features/gap_Xception.h5\", \n",
    "                 \"C:/Users/jiahu/Documents/dogs vs cats/tensorflow/features/gap_InceptionV3.h5\", \n",
    "                 \"C:/Users/jiahu/Documents/dogs vs cats/tensorflow/features/gap_VGG16.h5\", \n",
    "                 \"C:/Users/jiahu/Documents/dogs vs cats/tensorflow/features/gap_NASNetLarge.h5\"]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10688)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 10688)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10688)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 10689     \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(2021)\n",
    "\n",
    "input_tensor = tf.keras.Input(X_train.shape[1:])\n",
    "# x = tf.keras.layers.Dropout(0.99)(input_tensor)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(input_tensor)\n",
    "model = tf.keras.Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"C:/Users/jiahu/Documents/dogs vs cats/tensorflow/model/dog_cat_feature_extraction.h5\", \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False, \n",
    "                             mode='auto', \n",
    "                             save_freq='epoch')\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_acc', \n",
    "                      min_delta=0, \n",
    "                      patience=10, \n",
    "                      verbose=1, \n",
    "                      mode='auto')\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=2,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.1,\n",
    "                                            min_lr=0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "625/625 [==============================] - 4s 4ms/step - loss: 0.0466 - acc: 0.9823 - val_loss: 0.0295 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.99220, saving model to C:/Users/jiahu/Documents/dogs vs cats/tensorflow/model\\dog_cat_feature_extraction.h5\n",
      "Epoch 2/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.0099 - acc: 0.9969 - val_loss: 0.0310 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.99220 to 0.99440, saving model to C:/Users/jiahu/Documents/dogs vs cats/tensorflow/model\\dog_cat_feature_extraction.h5\n",
      "Epoch 3/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.0062 - acc: 0.9984 - val_loss: 0.0325 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99440\n",
      "Epoch 4/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0372 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.99440 to 0.99460, saving model to C:/Users/jiahu/Documents/dogs vs cats/tensorflow/model\\dog_cat_feature_extraction.h5\n",
      "Epoch 5/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0344 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99460\n",
      "Epoch 6/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0403 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99460\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 7.7703e-04 - acc: 0.9999 - val_loss: 0.0427 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99460\n",
      "Epoch 8/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 4.5195e-04 - acc: 0.9999 - val_loss: 0.0401 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99460\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.3249e-04 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99460\n",
      "Epoch 10/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.9777e-04 - acc: 0.9999 - val_loss: 0.0403 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99460\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 11/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.2159e-04 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99460\n",
      "Epoch 12/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.9341e-04 - acc: 0.9999 - val_loss: 0.0403 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99460\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 13/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.1801e-04 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99460\n",
      "Epoch 14/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.7290e-04 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99460\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 1000\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs = nb_epochs,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[checkpoint, early, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12500, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"D:/data science/cats and dogs/sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(\"D:/data science/cats and dogs/test/\", (224, 224), shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  label\n",
       "0   1.0  0.005\n",
       "1   2.0  0.005\n",
       "2   3.0  0.995\n",
       "3   4.0  0.995\n",
       "4   5.0  0.005\n",
       "5   6.0  0.005\n",
       "6   7.0  0.995\n",
       "7   8.0  0.995\n",
       "8   9.0  0.005\n",
       "9  10.0  0.005"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, file_dir in enumerate(test_generator.filenames):\n",
    "    file_name = file_dir.split('\\\\')[-1]\n",
    "    file_name, file_ext = file_name.split('.')\n",
    "    df.at[i-1, 'label'] = y_pred[i]\n",
    "\n",
    "df.to_csv('pred.csv', index=None)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
