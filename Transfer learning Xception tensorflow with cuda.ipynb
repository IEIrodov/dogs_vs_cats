{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_directory = 'D:/data science/cats and dogs/train/'\n",
    "\n",
    "image_size = (299,299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# image data preprocessing\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "class_mode = 'categorical' # for multi-class classification problem, use: class_mode = 'category' \n",
    "\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2 # set validation split\n",
    "    ) \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_directory,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode, # for multi-class classification problem, use 'category'\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_directory, # same directory as training data\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode, # for multi-class classification problem, use 'category'\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 204800)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 409602    \n",
      "=================================================================\n",
      "Total params: 21,271,082\n",
      "Trainable params: 409,602\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a model\n",
    "base_model = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"Xception_dogs_vs_cats.h5\", \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False, \n",
    "                             mode='auto', \n",
    "                             save_freq='epoch')\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_acc', \n",
    "                      min_delta=0, \n",
    "                      patience=10, \n",
    "                      verbose=1, \n",
    "                      mode='auto')\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=1,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.1,\n",
    "                                            min_lr=0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "625/625 [==============================] - 503s 795ms/step - loss: 11.1374 - acc: 0.9325 - val_loss: 10.2447 - val_acc: 0.9607\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.96074, saving model to Xception_dogs_vs_cats.h5\n",
      "Epoch 2/1000\n",
      "625/625 [==============================] - 375s 600ms/step - loss: 10.9833 - acc: 0.9586 - val_loss: 9.7187 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.96074 to 0.96334, saving model to Xception_dogs_vs_cats.h5\n",
      "Epoch 3/1000\n",
      "625/625 [==============================] - 375s 600ms/step - loss: 9.3364 - acc: 0.9675 - val_loss: 15.2073 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.96334\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 4/1000\n",
      "625/625 [==============================] - 375s 599ms/step - loss: 8.3380 - acc: 0.9720 - val_loss: 10.3132 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.96334 to 0.97055, saving model to Xception_dogs_vs_cats.h5\n",
      "Epoch 5/1000\n",
      "625/625 [==============================] - 374s 599ms/step - loss: 6.8417 - acc: 0.9734 - val_loss: 9.9082 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97055 to 0.97135, saving model to Xception_dogs_vs_cats.h5\n",
      "Epoch 6/1000\n",
      "625/625 [==============================] - 388s 622ms/step - loss: 6.6976 - acc: 0.9761 - val_loss: 9.1933 - val_acc: 0.9657\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97135\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 7/1000\n",
      "625/625 [==============================] - 443s 709ms/step - loss: 4.2657 - acc: 0.9800 - val_loss: 8.1795 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.97135\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 8/1000\n",
      "625/625 [==============================] - 373s 597ms/step - loss: 4.7626 - acc: 0.9803 - val_loss: 8.9996 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.97135\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 9/1000\n",
      "625/625 [==============================] - 373s 597ms/step - loss: 4.6180 - acc: 0.9776 - val_loss: 9.4488 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.97135\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 10/1000\n",
      "625/625 [==============================] - 375s 600ms/step - loss: 4.9348 - acc: 0.9790 - val_loss: 9.1042 - val_acc: 0.9673\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.97135\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "Epoch 11/1000\n",
      "625/625 [==============================] - 375s 600ms/step - loss: 5.0850 - acc: 0.9766 - val_loss: 8.0749 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.97135\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1e-09.\n",
      "Epoch 12/1000\n",
      "625/625 [==============================] - 375s 600ms/step - loss: 5.3390 - acc: 0.9773 - val_loss: 8.1556 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.97135\n",
      "Epoch 13/1000\n",
      "625/625 [==============================] - 376s 601ms/step - loss: 4.5201 - acc: 0.9797 - val_loss: 8.4348 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.97135\n",
      "Epoch 14/1000\n",
      "625/625 [==============================] - 384s 614ms/step - loss: 5.2380 - acc: 0.9786 - val_loss: 7.5786 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.97135 to 0.97256, saving model to Xception_dogs_vs_cats.h5\n",
      "Epoch 15/1000\n",
      "625/625 [==============================] - 382s 611ms/step - loss: 4.9975 - acc: 0.9794 - val_loss: 8.2240 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.97256\n",
      "Epoch 16/1000\n",
      "625/625 [==============================] - ETA: 0s - loss: 5.0768 - acc: 0.9794"
     ]
    }
   ],
   "source": [
    "# fit/train model\n",
    "\n",
    "nb_epochs = 1000\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = nb_epochs,\n",
    "    callbacks=[checkpoint, early, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
